{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e53756a-2e47-4f66-a853-63f4fc1d3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import hydroeval as he\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "605c0948-9480-4fc1-9d25-66934c21a28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zscore(x):\n",
    "    x = x.numpy()\n",
    "    x = np.where((x>0) & (x<1000) == True,x,0)\n",
    "    np_nanmean = np.nanmean(x)\n",
    "    np_nanstd = np.nanstd(x)\n",
    "    zscored = (x-np_nanmean)/np_nanstd\n",
    "    zscored = np.where(np.isfinite(zscored) == False,0,zscored)\n",
    "    return zscored\n",
    "\n",
    "def fill_NOwhiten(x):\n",
    "    a1 = torch.nanmean(x)\n",
    "    # b1 = np.nanstd(x)\n",
    "    y = torch.where(torch.isfinite(x)==False,a1,x)\n",
    "    # y = (y-a1)/b1\n",
    "    return y  \n",
    "\n",
    "class setter2(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y,z):\n",
    "        self.x = x[:z]\n",
    "        self.y = y[:z,:,:,:6]\n",
    "        # self.x = torch.load(x)[:z]\n",
    "        # self.y = torch.load(y)[:z]\n",
    "        self.std,self.mean = torch.std_mean(self.y)\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "        # self.y = self.y.reshape(self.y.shape[0],self.y.shape[3])\n",
    "#         rand_pts = torch.from_numpy(np.random.randint(0,self.x.shape[0],1000))\n",
    "#         self.x = self.x[rand_pts]\n",
    "#         self.y = self.y[rand_pts]\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "        y = self.y[idx].to('cuda')\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "class a(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super(a,self).__init__()\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "        chonz = 16\n",
    "#         # in layer\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=2, out_channels=chonz, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(2):\n",
    "            hidden_layers.append(torch.nn.Conv2d(in_channels=chonz, out_channels=chonz, kernel_size=3, padding=1, bias=False))\n",
    "            hidden_layers.append(torch.nn.BatchNorm2d(chonz))\n",
    "            hidden_layers.append(torch.nn.ReLU(inplace=True))\n",
    "        self.mid_layer = torch.nn.Sequential(*hidden_layers)\n",
    "        # out layer\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=chonz, out_channels=1, kernel_size=3, padding=1, bias=False) #anything below this is for shrinking \n",
    "        self.linear1 = torch.nn.Linear(self.XXXX,100) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(10,self.XX)\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.conv1(x))\n",
    "        out = self.mid_layer(out1)\n",
    "        o = self.conv3(out+out1)\n",
    "        o = self.linear1(o.view(o.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        o = self.relu(self.linear3(o))\n",
    "        o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "class a_simp(torch.nn.Module):\n",
    "    def __init__(self,channels,XXXX,XX):\n",
    "        super(a_simp,self).__init__()\n",
    "        self.channels = channels\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.linear1 = torch.nn.Linear(self.XXXX * self.channels,24) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(24,12)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(12,self.XX)\n",
    "    def forward(self, x):\n",
    "        o = self.linear1(x.view(x.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        # o = self.relu(self.linear3(o))\n",
    "        # o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab73015b-94f5-4f72-9a59-48c633448a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imz = torch.load('../data/traintest/COL_CLIP_traintest.pt')\n",
    "sf = torch.load('../data/traintest/COL_STFL_traintest.pt')\n",
    "\n",
    "imz_meanfilled_notwhitened = fill_NOwhiten(imz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691abe38-575e-42e4-b05e-c05d2b195010",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = imz[:,0]\n",
    "Qsb = imz[:,1]\n",
    "Qz = [Qs, Qsb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4382878d-fa82-445a-868f-0cd9648a69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscoredQs = []\n",
    "for y in Qs:\n",
    "    z = zscore(y)\n",
    "    zscoredQs.append(z)\n",
    "zscoredQs = torch.from_numpy(np.asarray(zscoredQs)).unsqueeze(1)\n",
    "\n",
    "#zscores Qsb\n",
    "zscoredQsb = []\n",
    "for y in Qsb:\n",
    "    z = zscore(y)\n",
    "    zscoredQsb.append(z)\n",
    "zscoredQsb = torch.from_numpy(np.asarray(zscoredQsb)).unsqueeze(1)\n",
    "zscoredQz = torch.cat((zscoredQs,zscoredQsb),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03d0eaba-c2af-4f0a-9ca3-31a5b0e06ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n",
      "105 52 53\n",
      "Training started at 2023-02-15 11:16:44\n",
      "epoch 0 train: [0.37]\n",
      "epoch 10 train: [0.74]\n",
      "epoch 20 train: [0.85]\n",
      "epoch 30 train: [0.89]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 54>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# nse_epoch_valid = he.evaluator(he.nse,val_pred.cpu().detach().numpy(),val_y.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m train: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnse_epoch_train\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m nse_during\u001b[38;5;241m.\u001b[39mappend(nse_epoch_train)\n\u001b[1;32m     88\u001b[0m t_loss\u001b[38;5;241m.\u001b[39mappend(t_e_loss\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_dataloader))\n",
      "File \u001b[0;32m/work/albertl_uri_edu/.conda/envs/f2f_2/lib/python3.10/site-packages/ipykernel/iostream.py:542\u001b[0m, in \u001b[0;36mOutStream.write\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI/O operation on closed file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     is_child \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_master_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# only touch the buffer in the IO thread to avoid races\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_lock:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "dset = setter2(zscoredQz,sf,210)\n",
    "# dset = setter2(imz_meanfilled_notwhitened,sf,210)\n",
    "\n",
    "epochs=400\n",
    "stop = 1\n",
    "east = timezone(\"US/Eastern\")\n",
    "data_split=.8\n",
    "cube_height = dset.x.shape[2]\n",
    "cube_width = dset.x.shape[3]\n",
    "batch_size=2\n",
    "\n",
    "# train_dset_size = int(data_split*len(dset))\n",
    "# valid_dset_size = int(len(dset) - train_dset_size)\n",
    "# train_dset, valid_dset = torch.utils.data.random_split(dset,[train_dset_size,valid_dset_size])\n",
    "\n",
    "\n",
    "train_size = int(.5*len(dset))\n",
    "valid_size = int(0.5*(len(dset) - train_size))\n",
    "test_size = int(len(dset)-train_size-valid_size)\n",
    "\n",
    "train_dset = torch.utils.data.TensorDataset(dset.x[:train_size],dset.y[:train_size])\n",
    "valid_dset = torch.utils.data.TensorDataset(dset.x[train_size: train_size + valid_size],\n",
    "                                            dset.y[train_size: train_size + valid_size])\n",
    "test_dset = torch.utils.data.TensorDataset(dset.x[train_size + valid_size:],\n",
    "                                            dset.y[train_size + valid_size:])\n",
    "print(len(train_dset),len(valid_dset),len(test_dset))\n",
    "\n",
    "# train = Subset(dset,range(0,train_dset_size))\n",
    "# valid = Subset(dset,range(train_dset_size,train_dset_size+valid_dset_size))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = a_simp(\n",
    "    channels = 2,\n",
    "    XXXX = dset.x.shape[2] * dset.x.shape[3],\n",
    "    XX = dset.y.shape[-1]\n",
    ")\n",
    "# model.apply(weights_init)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=150,verbose=False)\n",
    "\n",
    "print('Training started at {}'.format(datetime.now(east).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "e_time = []\n",
    "nse_during = []\n",
    "t0 = time.time()\n",
    "for i in range(epochs):\n",
    "    t_e_loss = 0\n",
    "    v_e_loss = 0\n",
    "    train_pred = torch.empty((0,1)).to('cuda')\n",
    "    train_y = torch.empty((0,1)).to('cuda')\n",
    "    # val_pred = torch.empty((0,1)).to('cuda')\n",
    "    # val_y = torch.empty((0,1)).to('cuda')\n",
    "    t00 = time.time()\n",
    "    model.train()\n",
    "    for idx,(x,y) in enumerate(train_dataloader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        predicted = model(x)   \n",
    "        train_pred = torch.cat((train_pred,predicted.reshape(-1,1)))\n",
    "        train_y = torch.cat((train_y,y.reshape(-1,1)))\n",
    "        loss = criterion(predicted.reshape(-1),y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_e_loss += loss.item()\n",
    "    for xx,yy in valid_dataloader:\n",
    "        xx = xx.cuda()\n",
    "        yy = yy.cuda()\n",
    "        v_pred = model(xx)\n",
    "        loss2 = criterion(v_pred.reshape(-1),yy.reshape(-1))\n",
    "        v_e_loss += loss2.item()\n",
    "        # val_pred = torch.cat((val_pred,v_pred.reshape(-1,1)))\n",
    "        # val_y = torch.cat((val_y,yy.reshape(-1,1)))\n",
    "    nse_epoch_train = he.evaluator(he.nse,train_pred.cpu().detach().numpy(),train_y.cpu().detach().numpy())\n",
    "    # nse_epoch_valid = he.evaluator(he.nse,val_pred.cpu().detach().numpy(),val_y.cpu().detach().numpy())\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch {i} train: {np.around(nse_epoch_train,2)}\")\n",
    "    nse_during.append(nse_epoch_train)\n",
    "    t_loss.append(t_e_loss/len(train_dataloader))\n",
    "    v_loss.append(v_e_loss/len(valid_dataloader))\n",
    "    t11 = time.time()\n",
    "    e_time.append(t11-t00)\n",
    "    if nse_epoch_train > stop:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print('Training time {} (minutes)'.format(np.format_float_positional((t1-t0)/60,precision=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3501ea59-8b1c-4286-bef2-bdd77c4b85ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10488"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "184 * 57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486f0f3-13f3-43f7-a128-1bdd2ec2b032",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-f2f_2)",
   "language": "python",
   "name": "conda-env-.conda-f2f_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
