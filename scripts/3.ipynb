{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "67696c63-b8a0-4e35-8f54-cbeff4600406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n"
     ]
    }
   ],
   "source": [
    "import arrow as A\n",
    "import scipy\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import itertools\n",
    "import torch\n",
    "import torchvision\n",
    "import xarray as xr\n",
    "import glob\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "def write(x,y):\n",
    "    with open(x,'a') as f:\n",
    "        f.write(y)\n",
    "        f.write('\\n')\n",
    "        f.close()\n",
    "    return _\n",
    "\n",
    "\n",
    "# def bandpass(x):\n",
    "#     mu = np.nanmean(x)\n",
    "#     sig = np.nanstd(x)\n",
    "#     return mu + (3*sig)\n",
    "\n",
    "# def xarr2torch(x):\n",
    "#         return torch.from_numpy(np.asarray(x)).unsqueeze(0).unsqueeze(0).float()\n",
    "    \n",
    "# def mse(x,y):\n",
    "#     e = y-x\n",
    "#     se = e**2\n",
    "    \n",
    "#     valcount = torch.where(torch.isnan(se)==False,1,0)\n",
    "#     valcount = torch.sum(valcount)\n",
    "\n",
    "#     sse = np.nansum(se)\n",
    "#     mse = np.nanmean(sse)\n",
    "#     return mse, valcount\n",
    "\n",
    "# def rmse(x,y):\n",
    "#     e = y-x\n",
    "#     se = e**2\n",
    "    \n",
    "#     valcount = torch.where(torch.isnan(se)==False,1,0)\n",
    "#     valcount = torch.sum(valcount)\n",
    "\n",
    "#     sse = np.nansum(se)\n",
    "#     mse = np.nanmean(sse)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     return rmse, valcount\n",
    "\n",
    "def fill_NOwhiten(x):\n",
    "    a1 = torch.nanmean(x)\n",
    "    # b1 = np.nanstd(x)\n",
    "    y = torch.where(torch.isfinite(x)==False,a1,x)\n",
    "    # y = (y-a1)/b1\n",
    "    return y,a1\n",
    "\n",
    "class Lnet(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super().__init__()\n",
    "        # in layer\n",
    "        flow_channels = 8\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=2, out_channels=flow_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu1 = torch.nn.ReLU(inplace=True)\n",
    "        # hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(2):\n",
    "            hidden_layers.append(torch.nn.Conv2d(in_channels=flow_channels, out_channels=flow_channels, kernel_size=3, padding=1, bias=False))\n",
    "            hidden_layers.append(torch.nn.BatchNorm2d(flow_channels))\n",
    "            hidden_layers.append(torch.nn.ReLU(inplace=True))\n",
    "        self.mid_layer = torch.nn.Sequential(*hidden_layers)\n",
    "        # out layer\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=flow_channels, out_channels=1, kernel_size=3, padding=1, bias=False)\n",
    "        \n",
    "        # out layer\n",
    "        self.linear1 = torch.nn.Linear(XXXX,100) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(10,XX)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu1(self.conv1(x))\n",
    "        out = self.mid_layer(out1)\n",
    "        o = self.conv3(out+out1)\n",
    "        o = self.linear1(o.view(o.size(0),-1))\n",
    "        o = self.relu1(self.linear2(o))\n",
    "        o = self.relu1(self.linear3(o))\n",
    "        o = self.relu1(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o\n",
    "    \n",
    "class dset_maker(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.load(x)\n",
    "        self.y = torch.load(y)\n",
    "        self.x,self.mean = fill_NOwhiten(self.x)\n",
    "        self.y,_ = fill_NOwhiten(self.y)\n",
    "    \n",
    "#         rand_pts = torch.from_numpy(np.random.randint(0,self.x.shape[0],100))\n",
    "        \n",
    "#         self.x = self.x[rand_pts]\n",
    "#         self.y = self.y[rand_pts]\n",
    "        \n",
    "#         self.combo = torch.cat((self.x.unsqueeze(0),self.y.unsqueeze(0)),0)\n",
    "        \n",
    "#         RVF = torchvision.transforms.RandomVerticalFlip()\n",
    "#         RHF = torchvision.transforms.RandomHorizontalFlip()\n",
    "        \n",
    "#         self.combo_transformed = RVF(RHF(self.combo))\n",
    "#         self.x = self.combo_transformed[0]\n",
    "#         self.y = self.combo_transformed[1]\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "#         x -= torch.min(x)\n",
    "#         x /= torch.max(x)\n",
    "        y = self.y[idx].to('cuda')\n",
    "#         y -= torch.min(y)\n",
    "#         y /= torch.max(y)\n",
    "\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "#         print(self.x.shape[0])\n",
    "        return self.x.shape[0]\n",
    "\n",
    "# def weights_init(m):\n",
    "#     classname = m.__class__.__name__\n",
    "#     if classname.find('Conv') != -1:\n",
    "#         torch.nn.init.normal_(m.weight.data,0.0,0.02)\n",
    "#     elif classname.find('BatchNorm') != -1:\n",
    "#         torch.nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "#         torch.nn.init.constant_(m.bias.data,0)  \n",
    "\n",
    "        \n",
    "class small_dset_creator(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = torch.load(x)[-1].reshape(-1,1,100,100)\n",
    "        # self.x0 = torch.clone(self.x)\n",
    "        self.y = torch.load(y)[-1].reshape(-1,1,100,100)\n",
    "        # self.y0 = torch.clone(self.y)\n",
    "        self.x,self.mean = fill_NOwhiten(self.x)\n",
    "        # self.y,_ = fill_NOwhiten(self.y)\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "        y = self.y[idx].to('cuda')\n",
    "        x0 = self.x0[idx]\n",
    "        y0 = self.y0[idx]\n",
    "        mean = self.mean\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]  \n",
    "    \n",
    "\n",
    "        \n",
    "# def foldit(x):\n",
    "#     x0 = x.reshape(-1,1,x.shape[2]*x.shape[3]).permute(1,2,0)\n",
    "#     fold = torch.nn.Fold(output_size=(land_mask.shape[2],land_mask.shape[3]),kernel_size=(patchsize,patchsize),stride=(patchsize,patchsize))\n",
    "#     return fold(x0)\n",
    "\n",
    "def train(model,epoch):\n",
    "    epoch_loss = 0\n",
    "    c=0\n",
    "    for x,y in train_dataloader:\n",
    "        c+=1\n",
    "\n",
    "        # target = y-x\n",
    "        predicted = model(x.cuda())\n",
    "\n",
    "        loss = criterion(predicted, y.cuda())\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    # scheduler.step()\n",
    "    print(f'Epoch {epoch} Train Mean MSE: {np.around(epoch_loss/len(train_dataloader),3)}')\n",
    "    \n",
    "def validate(model,epoch):\n",
    "    # validate.avg_psnr = 0\n",
    "    # avg_psnr = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        t_loss = 0\n",
    "        for xx,yy in valid_dataloader:\n",
    "            # target = yy-xx\n",
    "            predicted = model(xx.cuda())\n",
    "            mse = criterion(predicted, yy.cuda())\n",
    "            t_loss += mse.item()\n",
    "            # modis = yy.cpu().numpy().squeeze().squeeze();\n",
    "            # amsre = xx.cpu().numpy().squeeze();\n",
    "            # adj = predicted.cpu().numpy().squeeze();\n",
    "            # # psnr = 10 * np.log10(np.power(np.max(modis),2) / mean_squared_error(modis,amsre+adj))\n",
    "            # validate.avg_psnr += (psnr / len(valid_dataloader))\n",
    "        \n",
    "    print(f\"Epoch {epoch} Valid Mean MSE: {np.around(t_loss/len(valid_dataloader),3)}\")\n",
    "    \n",
    "# def save_checkpoint(state):\n",
    "#     model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "#     torch.save(state, model_out_path)\n",
    "#     print(f\"Checkpoint saved to {model_out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "283e4afd-1098-4102-b4e1-6ca67f41dba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "% training size (valid and test split equally from here) .8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 21 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# x = glob.glob('../data/traintest/*.pt')\n",
    "# for i in x:\n",
    "#     print(i)\n",
    "#     j = torch.load(i)\n",
    "#     print(j.shape)\n",
    "\n",
    "X0 = '../data/traintest/COL_CLIP_traintest.pt'\n",
    "Y0 = '../data/traintest/COL_STFL_traintest.pt'\n",
    "\n",
    "# Y0.shape\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "lr = 1e-3\n",
    "num_epochs=100\n",
    "fr = .02 #colorbar fraction\n",
    "blackRed = mpl.colors.ListedColormap(['red','black'])\n",
    "resultFolder = '../data/traintest_results/'\n",
    "train_size_prompt = float(input('% training size (valid and test split equally from here)'))\n",
    "\n",
    "dset = dset_maker(X0,Y0)\n",
    "train_size = int(train_size_prompt*len(dset))\n",
    "valid_size = int(0.5*(len(dset) - train_size))\n",
    "test_size = int(len(dset)-train_size-valid_size)\n",
    "\n",
    "print(train_size,valid_size,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b682df6-6857-409d-a8be-769da1bf46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 21 21\n"
     ]
    }
   ],
   "source": [
    "train_dset = torch.utils.data.TensorDataset(dset.x[:train_size],dset.y[:train_size])\n",
    "valid_dset = torch.utils.data.TensorDataset(dset.x[train_size: train_size + valid_size],\n",
    "                                            dset.y[train_size: train_size + valid_size])\n",
    "test_dset = torch.utils.data.TensorDataset(dset.x[train_size + valid_size:],\n",
    "                                            dset.y[train_size + valid_size:])\n",
    "print(len(train_dset),len(valid_dset),len(test_dset))\n",
    "\n",
    "\n",
    "\n",
    "# test_dset.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7298208c-151d-4506-b949-ebf538f5fd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b934ec65-109c-4ac8-aefa-c2356cbc33b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dset, \n",
    "                                                   batch_size=2, shuffle=False, num_workers=0)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dset, \n",
    "                                                   batch_size=1, shuffle=False, num_workers=0)\n",
    "model = Lnet(dset.x.shape[2] * dset.x.shape[3],dset.y.shape[-1]).cuda()\n",
    "# model.apply(weights_init)\n",
    "model.cuda()\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,8], gamma=.1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8abc6c72-72e8-4eda-8fe7-73e6ed215591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Valid Mean MSE: 21033773056.0\n",
      "Epoch 1 Train Mean MSE: 15862433478.095\n",
      "Epoch 2 Train Mean MSE: 15862417356.19\n",
      "Epoch 3 Train Mean MSE: 15862402099.81\n",
      "Epoch 4 Train Mean MSE: 15862386800.762\n",
      "Epoch 5 Train Mean MSE: 15862371894.857\n",
      "Epoch 6 Train Mean MSE: 15862356760.381\n",
      "Epoch 7 Train Mean MSE: 15862341641.143\n",
      "Epoch 8 Train Mean MSE: 15862326387.81\n",
      "Epoch 9 Train Mean MSE: 15862311411.81\n",
      "Epoch 10 Train Mean MSE: 15862296423.619\n",
      "Epoch 10 Valid Mean MSE: 21033593429.333\n",
      "Epoch 11 Train Mean MSE: 15862281325.714\n",
      "Epoch 12 Train Mean MSE: 15862266227.81\n",
      "Epoch 13 Train Mean MSE: 15862251157.333\n",
      "Epoch 14 Train Mean MSE: 15862235931.429\n",
      "Epoch 15 Train Mean MSE: 15862221068.19\n",
      "Epoch 16 Train Mean MSE: 15862205985.524\n",
      "Epoch 17 Train Mean MSE: 15862191018.667\n",
      "Epoch 18 Train Mean MSE: 15862175948.19\n",
      "Epoch 19 Train Mean MSE: 15862160612.571\n",
      "Epoch 20 Train Mean MSE: 15862145779.81\n",
      "Epoch 20 Valid Mean MSE: 21033425371.429\n",
      "Epoch 21 Train Mean MSE: 15862130730.667\n",
      "Epoch 22 Train Mean MSE: 15862115654.095\n",
      "Epoch 23 Train Mean MSE: 15862100516.571\n",
      "Epoch 24 Train Mean MSE: 15862085497.905\n",
      "Epoch 25 Train Mean MSE: 15862070524.952\n",
      "Epoch 26 Train Mean MSE: 15862055390.476\n",
      "Epoch 27 Train Mean MSE: 15862040341.333\n",
      "Epoch 28 Train Mean MSE: 15862025395.81\n",
      "Epoch 29 Train Mean MSE: 15862010133.333\n",
      "Epoch 30 Train Mean MSE: 15861995352.381\n",
      "Epoch 30 Valid Mean MSE: 21033257484.19\n",
      "Epoch 31 Train Mean MSE: 15861980163.048\n",
      "Epoch 32 Train Mean MSE: 15861965056.0\n",
      "Epoch 33 Train Mean MSE: 15861950089.143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [112]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      5\u001b[0m     validate(model,epoch)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      8\u001b[0m     validate(model,epoch)\n",
      "Input \u001b[0;32mIn [110]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m    177\u001b[0m     epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    179\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 180\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# scheduler.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_correction2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m    110\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = A.now('US/Eastern')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    if epoch == 1:\n",
    "        validate(model,epoch)\n",
    "    train(model,epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        validate(model,epoch)\n",
    "t1 = A.now('US/Eastern')\n",
    "\n",
    "# ds = small_dset_creator(amsre_lox[i],modis_lox[i])\n",
    "# dl = torch.utils.data.DataLoader(ds,shuffle=False)\n",
    "\n",
    "# model.eval()\n",
    "# pred = torch.empty(0,patchsize,patchsize)\n",
    "# with torch.no_grad():\n",
    "#     for idx,(x,y) in enumerate(dl):\n",
    "#         # target = y-x\n",
    "#         predicted = model(x)\n",
    "#         predicted = predicted.to('cpu')[0,0]\n",
    "#         predicted = torch.from_numpy(np.where(mask_patches[idx,0]>=.5, np.nan,predicted))\n",
    "#         if idx == 0:\n",
    "#             pred = predicted.unsqueeze(0).unsqueeze(1)\n",
    "#         else:\n",
    "#             pred = torch.cat((pred,predicted.unsqueeze(0).unsqueeze(1)),0)\n",
    "\n",
    "\n",
    "\n",
    "# filter_coast = torch.from_numpy(np.where(np.abs(pred) > np.abs(bandpass(pred)),np.nan,pred))\n",
    "\n",
    "# ##land mask is key\n",
    "\n",
    "# argo = torch.load(argo_lox[i])[-1] #-1 selects december\n",
    "\n",
    "# x0 = foldit(argo) #argo\n",
    "# x1 = foldit(ds.x0) #amsre\n",
    "# x2 = foldit(ds.y0) #modis\n",
    "# x3 = foldit(pred) #pred \n",
    "# x4 = foldit(filter_coast) #filtered pred\n",
    "\n",
    "# xs = [x0,x1,x2,x3,x4]\n",
    "# nm = ['argo','amsre','modis','pred','optim']\n",
    "\n",
    "# fig = plt.figure(figsize=(15,5))\n",
    "# gs = gridspec.GridSpec(3,5)\n",
    "# for j in range(5):\n",
    "#     fig.add_subplot(gs[0,j])\n",
    "#     plt.title(nm[j])\n",
    "#     plt.imshow(xs[j][0,0],cmap='jet',vmin=10,vmax=30)\n",
    "#     plt.axis('off')\n",
    "#     if j == 4:\n",
    "#         plt.colorbar(fraction=.02)\n",
    "\n",
    "#     fig.add_subplot(gs[1,j])\n",
    "#     plt.title(f\"{nm[j]}-{nm[0]}\")\n",
    "#     plt.imshow(xs[j][0,0]-xs[0][0,0],cmap='turbo_r',vmin=-2,vmax=2)\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     if j == 4:\n",
    "#         plt.colorbar(fraction=.02)\n",
    "\n",
    "#     fig.add_subplot(gs[2,j])\n",
    "#     plt.title(f\"{nm[j]}-{nm[2]}\")\n",
    "#     plt.imshow(xs[j][0,0]-xs[2][0,0],cmap='turbo_r',vmin=-2,vmax=2)\n",
    "#     plt.axis('off')\n",
    "\n",
    "#     if j == 4:\n",
    "#         plt.colorbar(fraction=.02)\n",
    "# plt.savefig(f'trapdoor/zultz/{i}.png',bbox_inches='tight')\n",
    "# plt.pause(0.05)\n",
    "\n",
    "\n",
    "# write(f'trapdoor/zultz/{i}res.txt',f'dif between variable and argo')\n",
    "# for idk,k in enumerate(xs):\n",
    "#     write(f'trapdoor/zultz/{i}res.txt',f'{nm[idk]}\\t\\t{rmse(k,x0)}')\n",
    "\n",
    "# write(f'trapdoor/zultz/{i}res.txt','\\n')\n",
    "\n",
    "# write(f'trapdoor/zultz/{i}res.txt',f'dif between variable and modis')\n",
    "# for idl,l in enumerate(xs):\n",
    "#     write(f'trapdoor/zultz/{i}res.txt',f'{nm[idl]}\\t\\t{rmse(l,x2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffd14157-572c-4267-9198-d107dd52105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'f2f' from '/work/albertl_uri_edu/f2f_holistic/scripts/f2f.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(f2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbfb99-a63e-44f2-9690-6afc604aa478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-f2f_2)",
   "language": "python",
   "name": "conda-env-.conda-f2f_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
