{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e53756a-2e47-4f66-a853-63f4fc1d3e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import hydroeval as he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab73015b-94f5-4f72-9a59-48c633448a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imz = torch.load('../data/traintest/COL_CLIP_traintest.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "691abe38-575e-42e4-b05e-c05d2b195010",
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs = imz[:,0]\n",
    "Qsb = imz[:,1]\n",
    "Qz = [Qs, Qsb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6a0136f7-3c49-4a45-95c2-0c7321b48f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 2, 46, 57])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zscoredQz.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "175374a0-8233-4799-b0e8-f98d81bb81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x):\n",
    "    x = x.numpy()\n",
    "    x = np.where((x>0) & (x<1000) == True,x,0)\n",
    "    np_nanmean = np.nanmean(x)\n",
    "    np_nanstd = np.nanstd(x)\n",
    "    zscored = (x-np_nanmean)/np_nanstd\n",
    "    zscored = np.where(np.isfinite(zscored) == False,0,zscored)\n",
    "    return zscored\n",
    "\n",
    "def fill_NOwhiten(x):\n",
    "    a1 = torch.nanmean(x)\n",
    "    # b1 = np.nanstd(x)\n",
    "    y = torch.where(torch.isfinite(x)==False,a1,x)\n",
    "    # y = (y-a1)/b1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a7380fe-ded4-4e49-b95f-7952fc2b70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imz_meanfilled_notwhitened = fill_NOwhiten(imz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4382878d-fa82-445a-868f-0cd9648a69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zscoredQs = []\n",
    "for y in Qs:\n",
    "    z = zscore(y)\n",
    "    zscoredQs.append(z)\n",
    "zscoredQs = torch.from_numpy(np.asarray(zscoredQs)).unsqueeze(1)\n",
    "\n",
    "#zscores Qsb\n",
    "zscoredQsb = []\n",
    "for y in Qsb:\n",
    "    z = zscore(y)\n",
    "    zscoredQsb.append(z)\n",
    "zscoredQsb = torch.from_numpy(np.asarray(zscoredQsb)).unsqueeze(1)\n",
    "zscoredQz = torch.cat((zscoredQs,zscoredQsb),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "605c0948-9480-4fc1-9d25-66934c21a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    " def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data,0.0,0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data,1.0,0.02)\n",
    "        torch.nn.init.constant_(m.bias.data,0)    \n",
    "\n",
    "class setter2(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y,z):\n",
    "        self.x = x[:z]\n",
    "        self.y = y[:z,:,:,:]\n",
    "        # self.x = torch.load(x)[:z]\n",
    "        # self.y = torch.load(y)[:z]\n",
    "        self.std,self.mean = torch.std_mean(self.y)\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "        # self.y = self.y.reshape(self.y.shape[0],self.y.shape[3])\n",
    "#         rand_pts = torch.from_numpy(np.random.randint(0,self.x.shape[0],1000))\n",
    "#         self.x = self.x[rand_pts]\n",
    "#         self.y = self.y[rand_pts]\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "        y = self.y[idx].to('cuda')\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "class a(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(a,self).__init__()\n",
    "        chonz = 2\n",
    "#         # in layer\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=2, out_channels=chonz, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(2):\n",
    "            hidden_layers.append(torch.nn.Conv2d(in_channels=chonz, out_channels=chonz, kernel_size=3, padding=1, bias=False))\n",
    "            hidden_layers.append(torch.nn.BatchNorm2d(chonz))\n",
    "            hidden_layers.append(torch.nn.ReLU(inplace=True))\n",
    "        self.mid_layer = torch.nn.Sequential(*hidden_layers)\n",
    "        # out layer\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=chonz, out_channels=1, kernel_size=3, padding=1, bias=False) #anything below this is for shrinking \n",
    "        self.linear1 = torch.nn.Linear(46*57,100) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(10,7)\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.conv1(x))\n",
    "        out = self.mid_layer(out1)\n",
    "        o = self.conv3(out+out1)\n",
    "        o = self.linear1(o.view(o.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        o = self.relu(self.linear3(o))\n",
    "        o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9ccfabb9-3d8d-4bc1-a762-1e38e1e62ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([210, 1, 1, 7])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf = torch.load('../data/traintest/COL_STFL_traintest.pt')\n",
    "sf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "775366f4-9464-4706-a72f-a4f2e85f4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dset = setter2(zscoredQz,sf,210)\n",
    "dset = setter2(imz_meanfilled_notwhitened,sf,210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "03d0eaba-c2af-4f0a-9ca3-31a5b0e06ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n",
      "105 52 53\n",
      "Training started at 2023-02-14 14:49:03\n",
      "epoch 0 train:\t [0.08]\n",
      "epoch 1 train:\t [0.13]\n",
      "epoch 2 train:\t [0.15]\n",
      "epoch 3 train:\t [0.16]\n",
      "epoch 4 train:\t [0.18]\n",
      "epoch 5 train:\t [0.2]\n",
      "epoch 6 train:\t [0.24]\n",
      "epoch 7 train:\t [0.29]\n",
      "epoch 8 train:\t [0.35]\n",
      "epoch 9 train:\t [0.43]\n",
      "epoch 10 train:\t [0.52]\n",
      "epoch 11 train:\t [0.62]\n",
      "epoch 12 train:\t [0.69]\n",
      "epoch 13 train:\t [0.72]\n",
      "epoch 14 train:\t [0.74]\n",
      "epoch 15 train:\t [0.75]\n",
      "epoch 16 train:\t [0.77]\n",
      "epoch 17 train:\t [0.78]\n",
      "epoch 18 train:\t [0.79]\n",
      "epoch 19 train:\t [0.79]\n",
      "epoch 20 train:\t [0.8]\n",
      "epoch 21 train:\t [0.8]\n",
      "epoch 22 train:\t [0.81]\n",
      "epoch 23 train:\t [0.82]\n",
      "epoch 24 train:\t [0.82]\n",
      "epoch 25 train:\t [0.82]\n",
      "epoch 26 train:\t [0.83]\n",
      "epoch 27 train:\t [0.83]\n",
      "epoch 28 train:\t [0.84]\n",
      "epoch 29 train:\t [0.84]\n",
      "epoch 30 train:\t [0.84]\n",
      "epoch 31 train:\t [0.85]\n",
      "epoch 32 train:\t [0.85]\n",
      "epoch 33 train:\t [0.85]\n",
      "epoch 34 train:\t [0.85]\n",
      "epoch 35 train:\t [0.85]\n",
      "epoch 36 train:\t [0.86]\n",
      "epoch 37 train:\t [0.86]\n",
      "epoch 38 train:\t [0.86]\n",
      "epoch 39 train:\t [0.86]\n",
      "Training time 0.12934 (minutes)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "epochs=40\n",
    "stop = .95\n",
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "east = timezone(\"US/Eastern\")\n",
    "data_split=.8\n",
    "cube_height = dset.x.shape[2]\n",
    "cube_width = dset.x.shape[3]\n",
    "batch_size=2\n",
    "\n",
    "# train_dset_size = int(data_split*len(dset))\n",
    "# valid_dset_size = int(len(dset) - train_dset_size)\n",
    "# train_dset, valid_dset = torch.utils.data.random_split(dset,[train_dset_size,valid_dset_size])\n",
    "\n",
    "\n",
    "train_size = int(.5*len(dset))\n",
    "valid_size = int(0.5*(len(dset) - train_size))\n",
    "test_size = int(len(dset)-train_size-valid_size)\n",
    "\n",
    "train_dset = torch.utils.data.TensorDataset(dset.x[:train_size],dset.y[:train_size])\n",
    "valid_dset = torch.utils.data.TensorDataset(dset.x[train_size: train_size + valid_size],\n",
    "                                            dset.y[train_size: train_size + valid_size])\n",
    "test_dset = torch.utils.data.TensorDataset(dset.x[train_size + valid_size:],\n",
    "                                            dset.y[train_size + valid_size:])\n",
    "print(len(train_dset),len(valid_dset),len(test_dset))\n",
    "\n",
    "# train = Subset(dset,range(0,train_dset_size))\n",
    "# valid = Subset(dset,range(train_dset_size,train_dset_size+valid_dset_size))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = a()\n",
    "model.apply(weights_init)\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "criterion = torch.nn.L1Loss()\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=150,verbose=False)\n",
    "\n",
    "print('Training started at {}'.format(datetime.now(east).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "e_time = []\n",
    "nse_during = []\n",
    "t0 = time.time()\n",
    "for i in range(epochs):\n",
    "    t_e_loss = 0\n",
    "    v_e_loss = 0\n",
    "    train_pred = torch.empty((0,1)).to('cuda')\n",
    "    train_y = torch.empty((0,1)).to('cuda')\n",
    "    # val_pred = torch.empty((0,1)).to('cuda')\n",
    "    # val_y = torch.empty((0,1)).to('cuda')\n",
    "    t00 = time.time()\n",
    "    model.train()\n",
    "    for idx,(x,y) in enumerate(train_dataloader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predicted = model(x)   \n",
    "        train_pred = torch.cat((train_pred,predicted.reshape(-1,1)))\n",
    "        train_y = torch.cat((train_y,y.reshape(-1,1)))\n",
    "        loss = criterion(predicted.reshape(-1),y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_e_loss += loss.item()\n",
    "    for xx,yy in valid_dataloader:\n",
    "        xx = xx.cuda()\n",
    "        yy = yy.cuda()\n",
    "        v_pred = model(xx)\n",
    "        loss2 = criterion(v_pred.reshape(-1),yy.reshape(-1))\n",
    "        v_e_loss += loss2.item()\n",
    "        # val_pred = torch.cat((val_pred,v_pred.reshape(-1,1)))\n",
    "        # val_y = torch.cat((val_y,yy.reshape(-1,1)))\n",
    "    nse_epoch_train = he.evaluator(he.nse,train_pred.cpu().detach().numpy(),train_y.cpu().detach().numpy())\n",
    "    # nse_epoch_valid = he.evaluator(he.nse,val_pred.cpu().detach().numpy(),val_y.cpu().detach().numpy())\n",
    "    print(f\"epoch {i} train:\\t {np.around(nse_epoch_train,2)}\")\n",
    "    nse_during.append(nse_epoch_train)\n",
    "    t_loss.append(t_e_loss/len(train_dataloader))\n",
    "    v_loss.append(v_e_loss/len(valid_dataloader))\n",
    "    t11 = time.time()\n",
    "    e_time.append(t11-t00)\n",
    "    if nse_epoch_train > stop:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print('Training time {} (minutes)'.format(np.format_float_positional((t1-t0)/60,precision=5)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-f2f_2)",
   "language": "python",
   "name": "conda-env-.conda-f2f_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
