{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925d7878-eb12-4987-b4d1-95f405014d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import hydroeval as he\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04df5d02-d523-4b83-bd0c-117afcb87bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x):\n",
    "    x = x.numpy()\n",
    "    x = np.where((x>0) & (x<1000) == True,x,0)\n",
    "    np_nanmean = np.nanmean(x)\n",
    "    np_nanstd = np.nanstd(x)\n",
    "    zscored = (x-np_nanmean)/np_nanstd\n",
    "    zscored = np.where(np.isfinite(zscored) == False,0,zscored)\n",
    "    return zscored\n",
    "\n",
    "def fill_NOwhiten(x):\n",
    "    a1 = torch.nanmean(x)\n",
    "    # b1 = np.nanstd(x)\n",
    "    y = torch.where(torch.isfinite(x)==False,a1,x)\n",
    "    # y = (y-a1)/b1\n",
    "    return y  \n",
    "\n",
    "class setter2(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y,z):\n",
    "        self.x = x[:z]\n",
    "        self.y = y[:z,:,:,:6]\n",
    "        # self.x = torch.load(x)[:z]\n",
    "        # self.y = torch.load(y)[:z]\n",
    "        self.std,self.mean = torch.std_mean(self.y)\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "        # self.y = self.y.reshape(self.y.shape[0],self.y.shape[3])\n",
    "#         rand_pts = torch.from_numpy(np.random.randint(0,self.x.shape[0],1000))\n",
    "#         self.x = self.x[rand_pts]\n",
    "#         self.y = self.y[rand_pts]\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "        y = self.y[idx].to('cuda')\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "class a(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super(a,self).__init__()\n",
    "        chonz = 16\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "#         # in layer\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=chonz, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(2):\n",
    "            hidden_layers.append(torch.nn.Conv2d(in_channels=chonz, out_channels=chonz, kernel_size=3, padding=1, bias=False))\n",
    "            hidden_layers.append(torch.nn.BatchNorm2d(chonz))\n",
    "            hidden_layers.append(torch.nn.ReLU(inplace=True))\n",
    "        self.mid_layer = torch.nn.Sequential(*hidden_layers)\n",
    "        # out layer\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=chonz, out_channels=1, kernel_size=3, padding=1, bias=False) #anything below this is for shrinking \n",
    "        self.linear1 = torch.nn.Linear(self.XXXX,100) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(10,self.XX)\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.conv1(x))\n",
    "        out = self.mid_layer(out1)\n",
    "        o = self.conv3(out+out1)\n",
    "        o = self.linear1(o.view(o.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        o = self.relu(self.linear3(o))\n",
    "        o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "class a_simp(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super(a_simp,self).__init__()\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.linear1 = torch.nn.Linear(self.XXXX,24) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(24,12)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(12,self.XX)\n",
    "    def forward(self, x):\n",
    "        o = self.linear1(x.view(x.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        # o = self.relu(self.linear3(o))\n",
    "        # o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79122068-ef0f-4875-9e70-419ba2b56e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imz = torch.load('../data/traintest/COL_MOGL_ZSCORE_traintest.pt')\n",
    "sf = torch.load('../data/traintest/COL_STFL_traintest.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a408365-55ca-4a45-9e32-70fdf3c0d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n",
      "168 21 21\n",
      "Training started at 2023-02-15 13:29:40\n",
      "epoch 0 train:\t [0.08]\n",
      "epoch 10 train:\t [0.83]\n",
      "epoch 20 train:\t [0.91]\n",
      "Training time 0.56568 (minutes)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "dset = setter2(imz,sf,210)\n",
    "# dset = setter2(imz_meanfilled_notwhitened,sf,210)\n",
    "\n",
    "epochs=200\n",
    "stop = .95\n",
    "east = timezone(\"US/Eastern\")\n",
    "data_split=.8\n",
    "cube_height = dset.x.shape[2]\n",
    "cube_width = dset.x.shape[3]\n",
    "batch_size=2\n",
    "\n",
    "# train_dset_size = int(data_split*len(dset))\n",
    "# valid_dset_size = int(len(dset) - train_dset_size)\n",
    "# train_dset, valid_dset = torch.utils.data.random_split(dset,[train_dset_size,valid_dset_size])\n",
    "\n",
    "\n",
    "train_size = int(data_split*len(dset))\n",
    "valid_size = int(0.5*(len(dset) - train_size))\n",
    "test_size = int(len(dset)-train_size-valid_size)\n",
    "\n",
    "train_dset = torch.utils.data.TensorDataset(dset.x[:train_size],dset.y[:train_size])\n",
    "valid_dset = torch.utils.data.TensorDataset(dset.x[train_size: train_size + valid_size],\n",
    "                                            dset.y[train_size: train_size + valid_size])\n",
    "test_dset = torch.utils.data.TensorDataset(dset.x[train_size + valid_size:],\n",
    "                                            dset.y[train_size + valid_size:])\n",
    "print(len(train_dset),len(valid_dset),len(test_dset))\n",
    "\n",
    "# train = Subset(dset,range(0,train_dset_size))\n",
    "# valid = Subset(dset,range(train_dset_size,train_dset_size+valid_dset_size))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = a(dset.x.shape[2] * dset.x.shape[3],dset.y.shape[-1])\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=150,verbose=False)\n",
    "\n",
    "print('Training started at {}'.format(datetime.now(east).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "e_time = []\n",
    "nse_during = []\n",
    "t0 = time.time()\n",
    "for i in range(epochs):\n",
    "    t_e_loss = 0\n",
    "    v_e_loss = 0\n",
    "    train_pred = torch.empty((0,1)).to('cuda')\n",
    "    train_y = torch.empty((0,1)).to('cuda')\n",
    "    # val_pred = torch.empty((0,1)).to('cuda')\n",
    "    # val_y = torch.empty((0,1)).to('cuda')\n",
    "    t00 = time.time()\n",
    "    model.train()\n",
    "    for idx,(x,y) in enumerate(train_dataloader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        predicted = model(x)   \n",
    "        train_pred = torch.cat((train_pred,predicted.reshape(-1,1)))\n",
    "        train_y = torch.cat((train_y,y.reshape(-1,1)))\n",
    "        loss = criterion(predicted.reshape(-1),y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_e_loss += loss.item()\n",
    "    for xx,yy in valid_dataloader:\n",
    "        xx = xx.cuda()\n",
    "        yy = yy.cuda()\n",
    "        v_pred = model(xx)\n",
    "        loss2 = criterion(v_pred.reshape(-1),yy.reshape(-1))\n",
    "        v_e_loss += loss2.item()\n",
    "        # val_pred = torch.cat((val_pred,v_pred.reshape(-1,1)))\n",
    "        # val_y = torch.cat((val_y,yy.reshape(-1,1)))\n",
    "    nse_epoch_train = he.evaluator(he.nse,train_pred.cpu().detach().numpy(),train_y.cpu().detach().numpy())\n",
    "    # nse_epoch_valid = he.evaluator(he.nse,val_pred.cpu().detach().numpy(),val_y.cpu().detach().numpy())\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch {i} train:\\t {np.around(nse_epoch_train,2)}\")\n",
    "    nse_during.append(nse_epoch_train)\n",
    "    t_loss.append(t_e_loss/len(train_dataloader))\n",
    "    v_loss.append(v_e_loss/len(valid_dataloader))\n",
    "    t11 = time.time()\n",
    "    e_time.append(t11-t00)\n",
    "    if nse_epoch_train > stop:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print('Training time {} (minutes)'.format(np.format_float_positional((t1-t0)/60,precision=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508c777-0814-4153-a941-9d6c75dbe8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-f2f_2)",
   "language": "python",
   "name": "conda-env-.conda-f2f_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
