{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925d7878-eb12-4987-b4d1-95f405014d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import hydroeval as he\n",
    "from datetime import datetime\n",
    "from pytz import timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04df5d02-d523-4b83-bd0c-117afcb87bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore(x):\n",
    "    x = x.numpy()\n",
    "    x = np.where((x>0) & (x<1000) == True,x,0)\n",
    "    np_nanmean = np.nanmean(x)\n",
    "    np_nanstd = np.nanstd(x)\n",
    "    zscored = (x-np_nanmean)/np_nanstd\n",
    "    zscored = np.where(np.isfinite(zscored) == False,0,zscored)\n",
    "    return zscored\n",
    "\n",
    "def fill_NOwhiten(x):\n",
    "    a1 = torch.nanmean(x)\n",
    "    # b1 = np.nanstd(x)\n",
    "    y = torch.where(torch.isfinite(x)==False,a1,x)\n",
    "    # y = (y-a1)/b1\n",
    "    return y  \n",
    "\n",
    "class setter2(torch.utils.data.Dataset):\n",
    "    def __init__(self,x,y,z):\n",
    "        self.x = x[:z]\n",
    "        self.y = y[:z,:,:,:6]\n",
    "        # self.x = torch.load(x)[:z]\n",
    "        # self.y = torch.load(y)[:z]\n",
    "        self.std,self.mean = torch.std_mean(self.y)\n",
    "        self.y = (self.y - self.mean)/self.std\n",
    "        # self.y = self.y.reshape(self.y.shape[0],self.y.shape[3])\n",
    "#         rand_pts = torch.from_numpy(np.random.randint(0,self.x.shape[0],1000))\n",
    "#         self.x = self.x[rand_pts]\n",
    "#         self.y = self.y[rand_pts]\n",
    "    def __getitem__(self,idx):\n",
    "        x = self.x[idx].to('cuda')\n",
    "        y = self.y[idx].to('cuda')\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "class a(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super(a,self).__init__()\n",
    "        chonz = 16\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "#         # in layer\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=chonz, kernel_size=3, padding=1, bias=False)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        # hidden layers\n",
    "        hidden_layers = []\n",
    "        for i in range(2):\n",
    "            hidden_layers.append(torch.nn.Conv2d(in_channels=chonz, out_channels=chonz, kernel_size=3, padding=1, bias=False))\n",
    "            hidden_layers.append(torch.nn.BatchNorm2d(chonz))\n",
    "            hidden_layers.append(torch.nn.ReLU(inplace=True))\n",
    "        self.mid_layer = torch.nn.Sequential(*hidden_layers)\n",
    "        # out layer\n",
    "        self.conv3 = torch.nn.Conv2d(in_channels=chonz, out_channels=1, kernel_size=3, padding=1, bias=False) #anything below this is for shrinking \n",
    "        self.linear1 = torch.nn.Linear(self.XXXX,100) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(100,50)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(10,self.XX)\n",
    "    def forward(self, x):\n",
    "        out1 = self.relu(self.conv1(x))\n",
    "        out = self.mid_layer(out1)\n",
    "        o = self.conv3(out+out1)\n",
    "        o = self.linear1(o.view(o.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        o = self.relu(self.linear3(o))\n",
    "        o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "class a_simp(torch.nn.Module):\n",
    "    def __init__(self,XXXX,XX):\n",
    "        super(a_simp,self).__init__()\n",
    "        self.XXXX = XXXX\n",
    "        self.XX = XX\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.linear1 = torch.nn.Linear(self.XXXX,24) ### this is what gets changed based on important switch\n",
    "        self.linear2 = torch.nn.Linear(24,12)\n",
    "        self.linear3 = torch.nn.Linear(50,20)\n",
    "        self.linear4 = torch.nn.Linear(20,10)\n",
    "        self.linear5 = torch.nn.Linear(12,self.XX)\n",
    "    def forward(self, x):\n",
    "        o = self.linear1(x.view(x.size(0),-1))\n",
    "        o = self.relu(self.linear2(o))\n",
    "        # o = self.relu(self.linear3(o))\n",
    "        # o = self.relu(self.linear4(o))\n",
    "        o = self.linear5(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79122068-ef0f-4875-9e70-419ba2b56e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "imz = torch.load('../data/traintest/COL_MOGL_ZSCORE_traintest.pt')\n",
    "sf = torch.load('../data/traintest/COL_STFL_traintest.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a408365-55ca-4a45-9e32-70fdf3c0d730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 ) NVIDIA GeForce GTX 1080 Ti available\n",
      "168 21 21\n",
      "Training started at 2023-02-15 15:16:03\n",
      "epoch 0 train:\t [0.47]\n",
      "epoch 10 train:\t [0.84]\n",
      "epoch 20 train:\t [0.93]\n",
      "epoch 30 train:\t [0.96]\n",
      "epoch 40 train:\t [0.98]\n",
      "epoch 50 train:\t [0.98]\n",
      "epoch 60 train:\t [0.99]\n",
      "epoch 70 train:\t [0.99]\n",
      "epoch 80 train:\t [0.99]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(predicted\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),y\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     67\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 68\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     t_e_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xx,yy \u001b[38;5;129;01min\u001b[39;00m valid_dataloader:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    139\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 141\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m           \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m           \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m           \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m           \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m           \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m           \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m           \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m           \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m           \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/_functional.py:105\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    103\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbias_correction2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[1;32m    110\u001b[0m param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(f'( {torch.cuda.device_count()} ) {torch.cuda.get_device_name(0)} available')\n",
    "\n",
    "dset = setter2(imz,sf,210)\n",
    "# dset = setter2(imz_meanfilled_notwhitened,sf,210)\n",
    "\n",
    "epochs=200\n",
    "stop = 1\n",
    "east = timezone(\"US/Eastern\")\n",
    "data_split=.8\n",
    "cube_height = dset.x.shape[2]\n",
    "cube_width = dset.x.shape[3]\n",
    "batch_size=2\n",
    "\n",
    "# train_dset_size = int(data_split*len(dset))\n",
    "# valid_dset_size = int(len(dset) - train_dset_size)\n",
    "# train_dset, valid_dset = torch.utils.data.random_split(dset,[train_dset_size,valid_dset_size])\n",
    "\n",
    "\n",
    "train_size = int(data_split*len(dset))\n",
    "valid_size = int(0.5*(len(dset) - train_size))\n",
    "test_size = int(len(dset)-train_size-valid_size)\n",
    "\n",
    "train_dset = torch.utils.data.TensorDataset(dset.x[:train_size],dset.y[:train_size])\n",
    "valid_dset = torch.utils.data.TensorDataset(dset.x[train_size: train_size + valid_size],\n",
    "                                            dset.y[train_size: train_size + valid_size])\n",
    "test_dset = torch.utils.data.TensorDataset(dset.x[train_size + valid_size:],\n",
    "                                            dset.y[train_size + valid_size:])\n",
    "print(len(train_dset),len(valid_dset),len(test_dset))\n",
    "\n",
    "# train = Subset(dset,range(0,train_dset_size))\n",
    "# valid = Subset(dset,range(train_dset_size,train_dset_size+valid_dset_size))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = a(dset.x.shape[2] * dset.x.shape[3],dset.y.shape[-1])\n",
    "model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer,step_size=150,verbose=False)\n",
    "\n",
    "print('Training started at {}'.format(datetime.now(east).strftime('%Y-%m-%d %H:%M:%S')))\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "e_time = []\n",
    "nse_during = []\n",
    "t0 = time.time()\n",
    "for i in range(epochs):\n",
    "    t_e_loss = 0\n",
    "    v_e_loss = 0\n",
    "    train_pred = torch.empty((0,1)).to('cuda')\n",
    "    train_y = torch.empty((0,1)).to('cuda')\n",
    "    # val_pred = torch.empty((0,1)).to('cuda')\n",
    "    # val_y = torch.empty((0,1)).to('cuda')\n",
    "    t00 = time.time()\n",
    "    model.train()\n",
    "    for idx,(x,y) in enumerate(train_dataloader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        optimizer.zero_grad()\n",
    " \n",
    "        predicted = model(x)   \n",
    "        train_pred = torch.cat((train_pred,predicted.reshape(-1,1)))\n",
    "        train_y = torch.cat((train_y,y.reshape(-1,1)))\n",
    "        loss = criterion(predicted.reshape(-1),y.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t_e_loss += loss.item()\n",
    "    for xx,yy in valid_dataloader:\n",
    "        xx = xx.cuda()\n",
    "        yy = yy.cuda()\n",
    "        v_pred = model(xx)\n",
    "        loss2 = criterion(v_pred.reshape(-1),yy.reshape(-1))\n",
    "        v_e_loss += loss2.item()\n",
    "        # val_pred = torch.cat((val_pred,v_pred.reshape(-1,1)))\n",
    "        # val_y = torch.cat((val_y,yy.reshape(-1,1)))\n",
    "    nse_epoch_train = he.evaluator(he.nse,train_pred.cpu().detach().numpy(),train_y.cpu().detach().numpy())\n",
    "    # nse_epoch_valid = he.evaluator(he.nse,val_pred.cpu().detach().numpy(),val_y.cpu().detach().numpy())\n",
    "    if i % 10 == 0:\n",
    "        print(f\"epoch {i} train:\\t {np.around(nse_epoch_train,2)}\")\n",
    "    nse_during.append(nse_epoch_train)\n",
    "    t_loss.append(t_e_loss/len(train_dataloader))\n",
    "    v_loss.append(v_e_loss/len(valid_dataloader))\n",
    "    t11 = time.time()\n",
    "    e_time.append(t11-t00)\n",
    "    if nse_epoch_train > stop:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print('Training time {} (minutes)'.format(np.format_float_positional((t1-t0)/60,precision=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d508c777-0814-4153-a941-9d6c75dbe8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-f2f_2)",
   "language": "python",
   "name": "conda-env-.conda-f2f_2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
